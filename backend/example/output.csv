,3
current_state,"{'external_observations': {'vision': '[SCREENSHOT]'}, 'internal_state': {'user_inputs': [], 'agent_outputs': ['PEFT offers parameter-efficient methods for finetuning large pretrained models. The traditional paradigm is to finetune all of a model’s parameters for each downstream task, but this is becoming exceedingly costly and impractical because of the enormous number of parameters in models today. Instead, it is more efficient to train a smaller number of prompt parameters or use a reparametrization method like low-rank adaptation (LoRA) to reduce the number of trainable parameters.\n\nThis quicktour will show you PEFT’s main features and how you can train or run inference on large models that would typically be inaccessible on consumer devices.\n\n**Train**\n\nEach PEFT method is defined by a PeftConfig class that stores all the important parameters for building a PeftModel. For example, to train with LoRA, load and create a LoraConfig class and specify the following parameters:\n- task_type: the task to train for (sequence-to-sequence language modeling in this case)\n- inference_mode: whether you’re using the model for inference or not\n- r: the dimension of the low-rank matrices\n- lora_alpha: the scaling factor for the low-rank matrices\n- lora_dropout: the dropout probability of the LoRA layers\n\n```python\nfrom peft import LoraConfig, TaskType\npeft_config = LoraConfig(task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1)\n```\n\nSee the LoraConfig reference for more details about other parameters you can adjust, such as the modules to target or the bias type.\n\nOnce the LoraConfig is setup, create a PeftModel with the get_peft_model() function. It takes a base model - which you can load from the Transformers library - and the LoraConfig containing the parameters for how to configure a model for training with LoRA.\n\nLoad the base model you want to finetune.\n\n```python\nfrom transformers import AutoModelForSeq2SeqLM\nmodel = AutoModelForSeq2SeqLM.from_pretrained(""bigscience/mt0-large"")\n```\n\nWrap the base model and peft_config with the get_peft_model() function to create a PeftModel. To get a sense of the number of trainable parameters in your model, use the print_trainable_parameters method.\n\n```python\nfrom peft import get_peft_model\nmodel = get_peft_model(model, peft_config)\nmodel.print']}}"
past,"{'previous_instructions': ""\n- Click on 'PEFT' in the documentation page.\n- Click on the 'Quicktour' link under the 'PEFT' section in the left sidebar.\n- Extract the content of the quicktour from the current page."", 'last_engine': 'Python Engine'}"
world_model_prompt,"
You are an AI system specialized in high level reasoning. Your goal is to generate instructions for other specialized AIs to perform web actions to reach objectives given by humans.
Your inputs are:
- objective ('str'): a high level description of the goal to achieve.
- previous_instructions ('str'): a list of previous steps taken to reach the objective.
- last_engine ('str'): the engine used in the previous step.
- current_state ('dict'): the state of the environment in YAML to use to perform the next step.

Your output are:
- thoughts ('str'): a list of thoughts in bullet points detailling your reasoning.
- next_engine ('str'): the engine to use for the next step.
- instruction ('str'): the instruction for the engine to perform the next step.

Here are the engines at your disposal:
- Python Engine: This engine is used when the task requires doing computing using the current state of the agent. 
It does not impact the outside world and does not navigate.
- Navigation Engine: This engine is used when the next step of the task requires further navigation to reach the goal. 
For instance it can be used to click on a link or to fill a form on a webpage. This engine is heavy and will do complex processing of the current HTML to decide which element to interact with.
- Navigation Controls: This engine is used to perform simple navigation. It is lighter than the Navigation Engine and is used when there is no need to interact with elements on the page.
Current controls are WAIT (to wait for a certain amount of time), BACK (to go back in the browser history), and SCAN (to take screenshots of the whole page).

Here are guidelines to follow:

# General guidelines
- The instruction should be detailled as possible and only contain the next step. 
- If the objective is already achieved in the screenshots, or the current state contains the demanded information, provide the next engine as 'COMPLETE'.
If information is to be returned, provide it in the instruction, if no information is to be returned, return '[NONE]' in the instruction.
Only provide directly the desired output in the instruction in cases where there is little data to provide. When complex and large data is to be returned, use the 'Python Engine' to return data.
- If previous instructions failed, denoted by [FAILED], reflect on the mistake, and try to leverage other visual and textual cues to reach the objective.

# Python Engine guidelines
- When providing an instruction to the Python Engine, do not provide any guideline on using visual information such as the screenshot, as the Python Engine does not have access to it.
- If the objective requires information gathering, and the previous step was a Navigation step, do not directly stop when seeing the information but use the Python Engine to gather as much information as possible.

# Navigation guidlines
- When providing information for the Navigation Engine, focus on elements that are most likely interactable, such as buttons, links, or forms and be precise in your description of the element to avoid ambiguitiy.
- If several steps have to be taken, provide instructions in bullet points.
- When further information on the current page is required, use the Navigation Controls's command 'SCAN' to take screenshots of the whole page. If the whole page has been scanned, there is no need to scan it again.

Here are previous examples:

Objective:  Go to the first issue you can find
Previous instructions: 
- Click on 'Issues' with the number '28' next to it.
- [FAILED] Click on 'Build and share place where people can suggest their use cases and results #225'
- [FAILED] Click on 'Build and share place where people can suggest their use cases and results #225'
Last engine: Navigation Engine
Current state: 
external_observations:
  vision: '[SCREENSHOT]'
internal_state:
  agent_outputs: []
  user_inputs: []

Thoughts:
- The current screenshot shows the issues page of the GitHub repository 'lavague-ai/LaVague'.
- The objective is to go to the first issue.
- Previous instructions have been unsuccessful. A new approach should be used.
- The '#225' seems not to be clickable and it might be relevant to devise an instruction that does not include it. 
Next engine: Navigation Engine
Instruction: Click on the first issue, with title 'Build and share place where people can suggest their use cases and results'
-----
Objective: Find When Llama 3 was released
Previous instructions:
- Click on 'meta-llama/Meta-Llama-3-8B'
Last engine: Navigation Engine
Current state:
external_observations:
  vision: '[SCREENSHOT]'
internal_state:
  agent_outputs: []
  user_inputs: []

Thoughts:
- The current page shows the model page for 'meta-llama/Meta-Llama-3-8B' on Hugging Face.
- Hugging Face, is a hub for AI models and datasets, where users can explore and interact with a variety of AI models.
- I am therefore on the right page to find information about the release date of 'Meta-Llama-3-8B'.
- However, only information visible right now is about legal and licensing information.
- Therefore the best next step is to use the 'SCAN' command to take a screenshots of the whole page to find the release date before taking further action.
Next engine: Navigation Controls
Instruction: SCAN
-----
Objective: Provide the code to get started with Gemini API
Previous instructions:
- Click on 'Read API docs'
- Click on 'Gemini API quickstart' on the menu
- SCAN
Last engine: Navigation Engine
Current state:
external_observations:
  vision: '[SCREENSHOTS]'
internal_state:
  agent_outputs: []
  user_inputs: []

Thoughts:
- The whole page has been scanned and current screenshot show the documentation page for the getting started of Gemini API.
- I am therefore on the right page to find the code to get started with the Gemini API.
- The next step is to provide the code to get started with the Gemini API.
- Therefore I need to use the Python Engine to generate the code to extract the code to get started with the Gemini API from this page.
Next engine: Python Engine
Instruction: Extract the code to get started with the Gemini API from the content of the page.
-----
Objective: What tech stack do we use?
Previous instructions: 
- [FAILED] Locate and click on the ""Technology Solutions"" link or section to find information about the tech stack.
- [FAILED] Click on the ""Technology Solutions"" section to explore detailed information about the tech stack.
Last engine: Navigation Engine
Current state: 
external_observations:
  vision: '[SCREENSHOT]'
internal_state:
  agent_outputs: []
  user_inputs: []

Thought:
- The screenshot shows a Notion webpage with information about a company called ACME INC.
- It has information about the company, their services, and departments.
- Previous instructions tried to click on ""Technology Solutions"" without success. This probably means that ""Technology Solutions"" is not clickable or reachable.
- Other strategies have to be pursued to reach the objective.
- There seems to be a link at the end of the screen about departments, with mention of a 'Software development' section that could be promising.
- The best next step is to explore this link to find information about the tech stack.
Next engine: Navigation Engine
Instruction: Click on the 'Software development' link.
-----
Objective: Provide a quick description of the author
Previous instructions:
- Click on 'About the author'
Last engine: Navigation Engine
Current state:
external_observations:
  vision: '[SCREENSHOT]'
internal_state:
  agent_outputs: []
  user_inputs: []

Thoughts:
- The screenshot shows a personal biography of the author.
- The goal is to provide a quick description of the author.
- This description is brief and can be directly extracted.
Next engine: COMPLETE
Instruction: The author is a software engineer with a passion for AI and machine learning. He has worked on various projects and has a blog where he shares his knowledge and experience.
-----
Objective: Provide description and price of their products
Previous instructions:
- Click on 'Products' in the menu
- Click on 'Platform overview' in the menu
Last engine: Navigation Engine
Current state:
external_observations:
  vision: '[SCREENSHOT]'
internal_state:
  agent_outputs: []
  user_inputs: []
  
Thoughts:
- The current page shows the product page of the company OpenAI
- The objective is to provide a description and price of their products.
- We seem to be on the right page to find the information.
- However, to answer the objective, gathering as much information as possible is necessary.
- The best next step is to use the Navigation Controls to take a screenshot of the whole page to extract the description and price of the products.
Next engine: Navigation Controls
Instruction: SCAN
-----
Objective: Provide the company’s mission statement
Previous instructions:
- Extract the text of the mission statement
Last engine: Python Engine
Current state:
external_observations:
  vision: '[SCREENSHOT]'
internal_state:
  agent_outputs: [""Our mission is to innovate and lead in the technology sector, creating solutions that drive progress and improve lives.""]
  user_inputs: []

Thoughts:
- The current screenshot shows the page about the company's vision and mision.
- The Python Engine was previously called to extract the mission statement.
- The agent_outputs contains the correct mission statement.
- Therefore, the goal has been achieved and we can output the mission statement.
Next engine: COMPLETE
Instruction: Our mission is to innovate and lead in the technology sector, creating solutions that drive progress and improve lives.
-----
Objective: Provide the address of the headquarters
Previous instructions:
- Click on 'Contact Us'
Last engine: Navigation Engine
Current state:
external_observations:
  vision: '[SCREENSHOT]'
internal_state:
  agent_outputs: []
  user_inputs: []
Thoughts:

- The screenshot shows the 'Contact Us' section of the website.
- The address of the headquarters is visible directly in the screenshot.
- The visual information is sufficient to extract and provide the address.
- No further processing is required as the address can be directly read from the screenshot.
Next engine: COMPLETE
Instruction: The address of the headquarters is 1234 Elm Street, Springfield, IL, 62701.
-----
Objective: Identify the list of services provided by the company
Previous instructions:
- Click on 'Services' in the menu
- SCAN
Last engine: Navigation Engine
Current state:
- external_observations:
  vision: '[SCREENSHOTS]'
internal_state:
  agent_outputs: []
  user_inputs: []
Thoughts:

- The whole page has been scanned, and the current screenshots show the services page of the company.
- The objective is to identify the list of services provided by the company.
- Since there is likely to be a significant amount of data to gather, it is better to use the Python Engine to extract this information reliably rather than directly using vision on it.
Next engine: Python Engine
Instruction: Extract the list of services provided by the company from the content of the page.
-----
Objective: Provide the date and location of the next company event
Previous instructions:
- Click on 'Events' in the menu
Last engine: Navigation Engine
Current state:
external_observations:
  vision: '[SCREENSHOT]'
internal_state:
  agent_outputs: []
  user_inputs: []
Thoughts:

- The current screenshot shows the 'Events' page.
- The objective is to provide the date and location of the next company event.
- The date and location of the next event are clearly mentioned in the screenshot.
- The objective can be easily achieved by directly reading the information from the screenshot.
Next engine: COMPLETE
Instruction: The next company event is on June 10, 2024, at the Downtown Convention Center, New York.


Here is the next objective:
Objective: Start the quicktour of PEFT
Previous instructions: 

- Click on 'PEFT' in the documentation page.
- Click on the 'Quicktour' link under the 'PEFT' section in the left sidebar.
- Extract the content of the quicktour from the current page.
Last engine: Python Engine
Current state: 
external_observations:
  vision: '[SCREENSHOT]'
internal_state:
  agent_outputs:
  - ""PEFT offers parameter-efficient methods for finetuning large pretrained models.\
    \ The traditional paradigm is to finetune all of a model\u2019s parameters for\
    \ each downstream task, but this is becoming exceedingly costly and impractical\
    \ because of the enormous number of parameters in models today. Instead, it is\
    \ more efficient to train a smaller number of prompt parameters or use a reparametrization\
    \ method like low-rank adaptation (LoRA) to reduce the number of trainable parameters.\n\
    \nThis quicktour will show you PEFT\u2019s main features and how you can train\
    \ or run inference on large models that would typically be inaccessible on consumer\
    \ devices.\n\n**Train**\n\nEach PEFT method is defined by a PeftConfig class that\
    \ stores all the important parameters for building a PeftModel. For example, to\
    \ train with LoRA, load and create a LoraConfig class and specify the following\
    \ parameters:\n- task_type: the task to train for (sequence-to-sequence language\
    \ modeling in this case)\n- inference_mode: whether you\u2019re using the model\
    \ for inference or not\n- r: the dimension of the low-rank matrices\n- lora_alpha:\
    \ the scaling factor for the low-rank matrices\n- lora_dropout: the dropout probability\
    \ of the LoRA layers\n\n```python\nfrom peft import LoraConfig, TaskType\npeft_config\
    \ = LoraConfig(task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, r=8, lora_alpha=32,\
    \ lora_dropout=0.1)\n```\n\nSee the LoraConfig reference for more details about\
    \ other parameters you can adjust, such as the modules to target or the bias type.\n\
    \nOnce the LoraConfig is setup, create a PeftModel with the get_peft_model() function.\
    \ It takes a base model - which you can load from the Transformers library - and\
    \ the LoraConfig containing the parameters for how to configure a model for training\
    \ with LoRA.\n\nLoad the base model you want to finetune.\n\n```python\nfrom transformers\
    \ import AutoModelForSeq2SeqLM\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\""\
    bigscience/mt0-large\"")\n```\n\nWrap the base model and peft_config with the get_peft_model()\
    \ function to create a PeftModel. To get a sense of the number of trainable parameters\
    \ in your model, use the print_trainable_parameters method.\n\n```python\nfrom\
    \ peft import get_peft_model\nmodel = get_peft_model(model, peft_config)\nmodel.print""
  user_inputs: []


Thought:
"
world_model_output,"### Thoughts:
- The current screenshot shows the ""Quicktour"" section of the PEFT documentation on Hugging Face.
- The objective is to start the quicktour of PEFT.
- The content of the quicktour has already been extracted by the Python Engine.
- The next step is to provide the extracted content to complete the objective.

### Next Engine:
COMPLETE

### Instruction:
PEFT offers parameter-efficient methods for finetuning large pretrained models. The traditional paradigm is to finetune all of a model’s parameters for each downstream task, but this is becoming exceedingly costly and impractical because of the enormous number of parameters in models today. Instead, it is more efficient to train a smaller number of prompt parameters or use a reparametrization method like low-rank adaptation (LoRA) to reduce the number of trainable parameters.

This quicktour will show you PEFT’s main features and how you can train or run inference on large models that would typically be inaccessible on consumer devices.

**Train**

Each PEFT method is defined by a PeftConfig class that stores all the important parameters for building a PeftModel. For example, to train with LoRA, load and create a LoraConfig class and specify the following parameters:
- task_type: the task to train for (sequence-to-sequence language modeling in this case)
- inference_mode: whether you’re using the model for inference or not
- r: the dimension of the low-rank matrices
"
world_model_inference_time,8.068857908248901
engine,
instruction,
engine_log,
success,
output,
code,
html,"<html class=""""><head>
		<meta charset=""utf-8"">
		<meta name=""viewport"" content=""width=device-width, initial-scale=1.0, user-scalable=no"">
		<meta name=""description"" content=""We’re on a journey to advance and democratize artificial intelligence through open source and open science."">
		<meta property=""fb:app_id"" content=""1321688464574422"">
		<meta name=""twitter:card"" content=""summary_large_image"">
		<meta name=""twitter:site"" content=""@huggingface"">
		<meta property=""og:title"" content=""PEFT"">
		<meta property=""og:type"" content=""website"">
		<meta property=""og:url"" content=""https://huggingface.co/docs/peft/index"">
		<meta property=""og:image"" content=""https://huggingface.co/front/thumbnails/docs/peft.png"">

		<link rel=""stylesheet"" href=""/front/build/kube-ffab781/style.css"">

		<link rel=""preconnect"" href=""https://fonts.gstatic.com"">
		<link href=""https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,200;0,300;0,400;0,600;0,700;0,900;1,200;1,300;1,400;1,600;1,700;1,900&amp;display=swap"" rel=""stylesheet"">
		<link href=""https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;600;700&amp;display=swap"" rel=""stylesheet"">

		<link rel=""stylesheet"" href=""https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css"" as=""style"" onload=""this.onload=null;this.rel='stylesheet'"">
		<noscript>
			<link rel=""stylesheet"" href=""https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css"" />
		</noscript>

		<link rel=""canonical"" href=""https://huggingface.co/docs/peft/index"">
<link rel=""alternate"" hreflang=""en"" href=""https://huggingface.co/docs/peft/en/index"">
<link rel=""alternate"" hreflang=""x-default"" href=""https://huggingface.co/docs/peft/index"">  

		<title>Quicktour</title>

		<script defer="""" data-domain=""huggingface.co"" event-loggedin=""false"" src=""/js/script.pageview-props.js""></script>
		<script>
			window.plausible =
				window.plausible ||
				function () {
					(window.plausible.q = window.plausible.q || []).push(arguments);
				};
		</script>
		<script type=""text/javascript"" src=""https://de5282c3ca0c.edge.sdk.awswaf.com/de5282c3ca0c/526cf06acb0d/challenge.js"" defer=""""></script>
	<script src=""https://js.stripe.com/v3/"" async=""""></script><link rel=""modulepreload"" as=""script"" crossorigin="""" href=""/front/build/kube-ffab781/SideMenu-304db656.js""><link rel=""modulepreload"" as=""script"" crossorigin="""" href=""/front/build/kube-ffab781/index-f4d3f1b9.js""><link rel=""modulepreload"" as=""script"" crossorigin="""" href=""/front/build/kube-ffab781/consts-0c059549.js""><link rel=""modulepreload"" as=""script"" crossorigin="""" href=""/front/build/kube-ffab781/SpotlightSearch-69dfbadb.js""><link rel=""modulepreload"" as=""script"" crossorigin="""" href=""/front/build/kube-ffab781/ModalBody-1d041c45.js""><link rel=""modulepreload"" as=""script"" crossorigin="""" href=""/front/build/kube-ffab781/urlWatcher-2cf9a1b6.js""><link rel=""modulepreload"" as=""script"" crossorigin="""" href=""/front/build/kube-ffab781/index-79e4fb58.js""><link rel=""modulepreload"" as=""script"" crossorigin="""" href=""/front/build/kube-ffab781/ThemeSwitcher-c57ed047.js""><link rel=""modulepreload"" as=""script"" crossorigin="""" href=""/front/build/kube-ffab781/IconCog-b3333a36.js""><link rel=""modulepreload"" as=""script"" crossorigin="""" href=""/front/build/kube-ffab781/IconCogFlat-98af81a9.js""><link rel=""modulepreload"" as=""script"" crossorigin="""" href=""/front/build/kube-ffab781/IconSun-e76e8080.js""><link rel=""modulepreload"" as=""script"" crossorigin="""" href=""/front/build/kube-ffab781/IconPaperClip-8b15b582.js""><link rel=""modulepreload"" as=""script"" crossorigin="""" href=""/front/build/kube-ffab781/stores-ade8cb1a.js""><link rel=""modulepreload"" as=""script"" crossorigin="""" href=""/front/build/kube-ffab781/DocFooterNav-5ee9f367.js""><link rel=""modulepreload"" as=""script"" crossorigin="""" href=""/front/build/kube-ffab781/CourseCompleteButton-d7c8fb9c.js""><link rel=""modulepreload"" as=""script"" crossorigin="""" href=""/front/build/kube-ffab781/SubSideMenu-6f5fcc49.js""><link rel=""stylesheet"" href=""/docs/peft/v0.11.0/en/_app/immutable/assets/0.e3b0c442.css""><link rel=""modulepreload"" as=""script"" crossorigin="""" href=""/docs/peft/v0.11.0/en/_app/immutable/nodes/1.7877e936.js""><link rel=""modulepreload"" as=""script"" crossorigin="""" href=""/docs/peft/v0.11.0/en/_app/immutable/nodes/42.95640295.js""><link rel=""modulepreload"" as=""script"" crossorigin="""" href=""/docs/peft/v0.11.0/en/_app/immutable/chunks/Tip.9268b0ca.js""><link rel=""modulepreload"" as=""script"" crossorigin="""" href=""/docs/peft/v0.11.0/en/_app/immutable/chunks/CodeBlock.34f0a53d.js""><meta name=""hf:doc:metadata"" content=""{&quot;title&quot;:&quot;Quicktour&quot;,&quot;local&quot;:&quot;quicktour&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;Train&quot;,&quot;local&quot;:&quot;train&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;Save model&quot;,&quot;local&quot;:&quot;save-model&quot;,&quot;sections&quot;:[],&quot;depth&quot;:3}],&quot;depth&quot;:2},{&quot;title&quot;:&quot;Inference&quot;,&quot;local&quot;:&quot;inference&quot;,&quot;sections&quot;:[],&quot;depth&quot;:2},{&quot;title&quot;:&quot;Next steps&quot;,&quot;local&quot;:&quot;next-steps&quot;,&quot;sections&quot;:[],&quot;depth&quot;:2}],&quot;depth&quot;:1}""></head>
	<body class=""flex flex-col min-h-screen bg-white dark:bg-gray-950 text-black DocBuilderPage"">
		<div class=""flex min-h-screen flex-col"">
	<div class=""SVELTE_HYDRATER contents"" data-target=""MainHeader"" data-props=""{&quot;classNames&quot;:&quot;&quot;,&quot;isWide&quot;:true,&quot;isZh&quot;:false}""><header class=""border-b border-gray-100 ""><div class=""w-full px-4  flex h-16 items-center""><div class=""flex flex-1 items-center""><a class=""mr-5 flex flex-none items-center lg:mr-6"" href=""/""><img alt=""Hugging Face's logo"" class=""w-7 md:mr-2"" src=""/front/assets/huggingface_logo-noborder.svg""> <span class=""hidden whitespace-nowrap text-lg font-bold md:block"">Hugging Face</span></a> <div class=""relative flex-1 lg:max-w-sm mr-2 sm:mr-4 md:mr-3 xl:mr-6""><input autocomplete=""off"" class=""w-full dark:bg-gray-950 pl-8 form-input-alt h-9 pr-3 focus:shadow-xl "" name="""" placeholder=""Search models, datasets, users..."" spellcheck=""false"" type=""text""> <svg class=""absolute left-2.5 text-gray-400 top-1/2 transform -translate-y-1/2"" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" focusable=""false"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 32 32""><path d=""M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z"" fill=""currentColor""></path></svg> </div> <div class=""flex flex-none items-center justify-center p-0.5 place-self-stretch lg:hidden""><button class=""relative z-40 flex h-6 w-8 items-center justify-center"" type=""button""><svg width=""1em"" height=""1em"" viewBox=""0 0 10 10"" class=""text-xl"" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" focusable=""false"" role=""img"" preserveAspectRatio=""xMidYMid meet"" fill=""currentColor""><path fill-rule=""evenodd"" clip-rule=""evenodd"" d=""M1.65039 2.9999C1.65039 2.8066 1.80709 2.6499 2.00039 2.6499H8.00039C8.19369 2.6499 8.35039 2.8066 8.35039 2.9999C8.35039 3.1932 8.19369 3.3499 8.00039 3.3499H2.00039C1.80709 3.3499 1.65039 3.1932 1.65039 2.9999ZM1.65039 4.9999C1.65039 4.8066 1.80709 4.6499 2.00039 4.6499H8.00039C8.19369 4.6499 8.35039 4.8066 8.35039 4.9999C8.35039 5.1932 8.19369 5.3499 8.00039 5.3499H2.00039C1.80709 5.3499 1.65039 5.1932 1.65039 4.9999ZM2.00039 6.6499C1.80709 6.6499 1.65039 6.8066 1.65039 6.9999C1.65039 7.1932 1.80709 7.3499 2.00039 7.3499H8.00039C8.19369 7.3499 8.35039 7.1932 8.35039 6.9999C8.35039 6.8066 8.19369 6.6499 8.00039 6.6499H2.00039Z""></path></svg> </button> </div></div> <nav aria-label=""Main"" class=""ml-auto hidden lg:block""><ul class=""flex items-center space-x-1.5 xl:space-x-2""><li><a class=""group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-indigo-700"" href=""/models""><svg class=""mr-1.5 text-gray-400 group-hover:text-indigo-500"" style="""" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" focusable=""false"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 24 24""><path class=""uim-quaternary"" d=""M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z"" opacity="".25"" fill=""currentColor""></path><path class=""uim-tertiary"" d=""M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z"" opacity="".5"" fill=""currentColor""></path><path class=""uim-primary"" d=""M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z"" fill=""currentColor""></path></svg> Models</a></li><li><a class=""group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-red-700"" href=""/datasets""><svg class=""mr-1.5 text-gray-400 group-hover:text-red-500"" style="""" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" focusable=""false"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 25 25""><ellipse cx=""12.5"" cy=""5"" fill=""currentColor"" fill-opacity=""0.25"" rx=""7.5"" ry=""2""></ellipse><path d=""M12.5 15C16.6421 15 20 14.1046 20 13V20C20 21.1046 16.6421 22 12.5 22C8.35786 22 5 21.1046 5 20V13C5 14.1046 8.35786 15 12.5 15Z"" fill=""currentColor"" opacity=""0.5""></path><path d=""M12.5 7C16.6421 7 20 6.10457 20 5V11.5C20 12.6046 16.6421 13.5 12.5 13.5C8.35786 13.5 5 12.6046 5 11.5V5C5 6.10457 8.35786 7 12.5 7Z"" fill=""currentColor"" opacity=""0.5""></path><path d=""M5.23628 12C5.08204 12.1598 5 12.8273 5 13C5 14.1046 8.35786 15 12.5 15C16.6421 15 20 14.1046 20 13C20 12.8273 19.918 12.1598 19.7637 12C18.9311 12.8626 15.9947 13.5 12.5 13.5C9.0053 13.5 6.06886 12.8626 5.23628 12Z"" fill=""currentColor""></path></svg> Datasets</a></li><li><a class=""group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-blue-700"" href=""/spaces""><svg class=""mr-1.5 text-gray-400 group-hover:text-blue-500"" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" focusable=""false"" role=""img"" width=""1em"" height=""1em"" viewBox=""0 0 25 25""><path opacity="".5"" d=""M6.016 14.674v4.31h4.31v-4.31h-4.31ZM14.674 14.674v4.31h4.31v-4.31h-4.31ZM6.016 6.016v4.31h4.31v-4.31h-4.31Z"" fill=""currentColor""></path><path opacity="".75"" fill-rule=""evenodd"" clip-rule=""evenodd"" d=""M3 4.914C3 3.857 3.857 3 4.914 3h6.514c.884 0 1.628.6 1.848 1.414a5.171 5.171 0 0 1 7.31 7.31c.815.22 1.414.964 1.414 1.848v6.514A1.914 1.914 0 0 1 20.086 22H4.914A1.914 1.914 0 0 1 3 20.086V4.914Zm3.016 1.102v4.31h4.31v-4.31h-4.31Zm0 12.968v-4.31h4.31v4.31h-4.31Zm8.658 0v-4.31h4.31v4.31h-4.31Zm0-10.813a2.155 2.155 0 1 1 4.31 0 2.155 2.155 0 0 1-4.31 0Z"" fill=""currentColor""></path><path opacity="".25"" d=""M16.829 6.016a2.155 2.155 0 1 0 0 4.31 2.155 2.155 0 0 0 0-4.31Z"" fill=""currentColor""></path></svg> Spaces</a></li><li><a class=""group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-yellow-700"" href=""/posts""><svg class=""mr-1.5 text-gray-400 group-hover:text-yellow-500 !text-yellow-500"" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" focusable=""false"" role=""img"" width=""1em"" height=""1em"" viewBox=""0 0 12 12"" preserveAspectRatio=""xMidYMid meet""><path fill=""currentColor"" fill-rule=""evenodd"" d=""M3.73 2.4A4.25 4.25 0 1 1 6 10.26H2.17l-.13-.02a.43.43 0 0 1-.3-.43l.01-.06a.43.43 0 0 1 .12-.22l.84-.84A4.26 4.26 0 0 1 3.73 2.4Z"" clip-rule=""evenodd""></path></svg> Posts</a></li><li><a class=""group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-yellow-700"" href=""/docs""><svg xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" role=""img"" class=""mr-1.5 text-gray-400 group-hover:text-yellow-500"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 32 32""><path opacity=""0.5"" d=""M20.9022 5.10334L10.8012 10.8791L7.76318 9.11193C8.07741 8.56791 8.5256 8.11332 9.06512 7.7914L15.9336 3.73907C17.0868 3.08811 18.5002 3.26422 19.6534 3.91519L19.3859 3.73911C19.9253 4.06087 20.5879 4.56025 20.9022 5.10334Z"" fill=""currentColor""></path><path d=""M10.7999 10.8792V28.5483C10.2136 28.5475 9.63494 28.4139 9.10745 28.1578C8.5429 27.8312 8.074 27.3621 7.74761 26.7975C7.42122 26.2327 7.24878 25.5923 7.24756 24.9402V10.9908C7.25062 10.3319 7.42358 9.68487 7.74973 9.1123L10.7999 10.8792Z"" fill=""currentColor"" fill-opacity=""0.75""></path><path fill-rule=""evenodd"" clip-rule=""evenodd"" d=""M21.3368 10.8499V6.918C21.3331 6.25959 21.16 5.61234 20.8346 5.03949L10.7971 10.8727L10.8046 10.874L21.3368 10.8499Z"" fill=""currentColor""></path><path opacity=""0.5"" d=""M21.7937 10.8488L10.7825 10.8741V28.5486L21.7937 28.5234C23.3344 28.5234 24.5835 27.2743 24.5835 25.7335V13.6387C24.5835 12.0979 23.4365 11.1233 21.7937 10.8488Z"" fill=""currentColor""></path></svg> Docs</a></li> <li class=""max-2xl:hidden""><div class=""relative ""><button class=""px-2 py-0.5 group hover:text-green-700 dark:hover:text-gray-400 flex items-center "" type=""button""><svg class=""mr-1.5 text-gray-400 group-hover:text-green-500"" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" focusable=""false"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 24 24""><path class=""uim-tertiary"" d=""M19 6H5a3 3 0 0 0-3 3v2.72L8.837 14h6.326L22 11.72V9a3 3 0 0 0-3-3z"" opacity="".5"" fill=""currentColor""></path><path class=""uim-primary"" d=""M10 6V5h4v1h2V5a2.002 2.002 0 0 0-2-2h-4a2.002 2.002 0 0 0-2 2v1h2zm-1.163 8L2 11.72V18a3.003 3.003 0 0 0 3 3h14a3.003 3.003 0 0 0 3-3v-6.28L15.163 14H8.837z"" fill=""currentColor""></path></svg> Solutions </button> </div></li> <li><a class=""group flex items-center px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-400"" href=""/pricing"">Pricing</a></li> <li><div class=""relative group""><button class=""px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-600 flex items-center "" type=""button""><svg class=""mr-1.5 text-gray-500 w-5 group-hover:text-gray-400 dark:text-gray-300 dark:group-hover:text-gray-400"" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" focusable=""false"" role=""img"" width=""1em"" height=""1em"" viewBox=""0 0 32 18"" preserveAspectRatio=""xMidYMid meet""><path fill-rule=""evenodd"" clip-rule=""evenodd"" d=""M14.4504 3.30221C14.4504 2.836 14.8284 2.45807 15.2946 2.45807H28.4933C28.9595 2.45807 29.3374 2.836 29.3374 3.30221C29.3374 3.76842 28.9595 4.14635 28.4933 4.14635H15.2946C14.8284 4.14635 14.4504 3.76842 14.4504 3.30221Z"" fill=""currentColor""></path><path fill-rule=""evenodd"" clip-rule=""evenodd"" d=""M14.4504 9.00002C14.4504 8.53382 14.8284 8.15588 15.2946 8.15588H28.4933C28.9595 8.15588 29.3374 8.53382 29.3374 9.00002C29.3374 9.46623 28.9595 9.84417 28.4933 9.84417H15.2946C14.8284 9.84417 14.4504 9.46623 14.4504 9.00002Z"" fill=""currentColor""></path><path fill-rule=""evenodd"" clip-rule=""evenodd"" d=""M14.4504 14.6978C14.4504 14.2316 14.8284 13.8537 15.2946 13.8537H28.4933C28.9595 13.8537 29.3374 14.2316 29.3374 14.6978C29.3374 15.164 28.9595 15.542 28.4933 15.542H15.2946C14.8284 15.542 14.4504 15.164 14.4504 14.6978Z"" fill=""currentColor""></path><path fill-rule=""evenodd"" clip-rule=""evenodd"" d=""M1.94549 6.87377C2.27514 6.54411 2.80962 6.54411 3.13928 6.87377L6.23458 9.96907L9.32988 6.87377C9.65954 6.54411 10.194 6.54411 10.5237 6.87377C10.8533 7.20343 10.8533 7.73791 10.5237 8.06756L6.23458 12.3567L1.94549 8.06756C1.61583 7.73791 1.61583 7.20343 1.94549 6.87377Z"" fill=""currentColor""></path></svg>  </button> </div></li> <li><hr class=""h-5 w-0.5 border-none bg-gray-100 dark:bg-gray-800""></li> <li><a class=""block cursor-pointer px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-400"" href=""/login"">Log In</a></li> <li><a class=""rounded-full border border-transparent bg-gray-900 px-3 py-1 leading-none text-white hover:border-black hover:bg-white hover:text-black"" href=""/join"">Sign Up</a></li></ul></nav></div></header></div>
	
	
	
	<div class=""SVELTE_HYDRATER contents"" data-target=""SSOBanner"" data-props=""{}""></div>
	

	<main class=""flex flex-1 flex-col""><div class=""relative lg:flex"" id=""hf-doc-container""><div class=""sticky top-0 z-20 self-start""><div class=""SVELTE_HYDRATER contents"" data-target=""SideMenu"" data-props=""{&quot;chapters&quot;:[{&quot;title&quot;:&quot;Get started&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;🤗 PEFT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;index&quot;,&quot;url&quot;:&quot;/docs/peft/index&quot;},{&quot;title&quot;:&quot;Quicktour&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;quicktour&quot;,&quot;url&quot;:&quot;/docs/peft/quicktour&quot;},{&quot;title&quot;:&quot;Installation&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;install&quot;,&quot;url&quot;:&quot;/docs/peft/install&quot;}]},{&quot;title&quot;:&quot;Tutorial&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Configurations and models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tutorial/peft_model_config&quot;,&quot;url&quot;:&quot;/docs/peft/tutorial/peft_model_config&quot;},{&quot;title&quot;:&quot;Integrations&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;tutorial/peft_integrations&quot;,&quot;url&quot;:&quot;/docs/peft/tutorial/peft_integrations&quot;}]},{&quot;title&quot;:&quot;PEFT method guides&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Prompt-based methods&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;task_guides/prompt_based_methods&quot;,&quot;url&quot;:&quot;/docs/peft/task_guides/prompt_based_methods&quot;},{&quot;title&quot;:&quot;LoRA methods&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;task_guides/lora_based_methods&quot;,&quot;url&quot;:&quot;/docs/peft/task_guides/lora_based_methods&quot;},{&quot;title&quot;:&quot;IA3&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;task_guides/ia3&quot;,&quot;url&quot;:&quot;/docs/peft/task_guides/ia3&quot;}]},{&quot;title&quot;:&quot;Developer guides&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Model merging&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;developer_guides/model_merging&quot;,&quot;url&quot;:&quot;/docs/peft/developer_guides/model_merging&quot;},{&quot;title&quot;:&quot;Quantization&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;developer_guides/quantization&quot;,&quot;url&quot;:&quot;/docs/peft/developer_guides/quantization&quot;},{&quot;title&quot;:&quot;LoRA&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;developer_guides/lora&quot;,&quot;url&quot;:&quot;/docs/peft/developer_guides/lora&quot;},{&quot;title&quot;:&quot;Custom models&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;developer_guides/custom_models&quot;,&quot;url&quot;:&quot;/docs/peft/developer_guides/custom_models&quot;},{&quot;title&quot;:&quot;Adapter injection&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;developer_guides/low_level_api&quot;,&quot;url&quot;:&quot;/docs/peft/developer_guides/low_level_api&quot;},{&quot;title&quot;:&quot;Mixed adapter types&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;developer_guides/mixed_models&quot;,&quot;url&quot;:&quot;/docs/peft/developer_guides/mixed_models&quot;},{&quot;title&quot;:&quot;Contribute to PEFT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;developer_guides/contributing&quot;,&quot;url&quot;:&quot;/docs/peft/developer_guides/contributing&quot;},{&quot;title&quot;:&quot;Troubleshooting&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;developer_guides/troubleshooting&quot;,&quot;url&quot;:&quot;/docs/peft/developer_guides/troubleshooting&quot;},{&quot;title&quot;:&quot;PEFT checkpoint format&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;developer_guides/checkpoint&quot;,&quot;url&quot;:&quot;/docs/peft/developer_guides/checkpoint&quot;}]},{&quot;title&quot;:&quot;🤗 Accelerate integrations&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;DeepSpeed&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;accelerate/deepspeed&quot;,&quot;url&quot;:&quot;/docs/peft/accelerate/deepspeed&quot;},{&quot;title&quot;:&quot;Fully Sharded Data Parallel&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;accelerate/fsdp&quot;,&quot;url&quot;:&quot;/docs/peft/accelerate/fsdp&quot;}]},{&quot;title&quot;:&quot;Conceptual guides&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Adapters&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;conceptual_guides/adapter&quot;,&quot;url&quot;:&quot;/docs/peft/conceptual_guides/adapter&quot;},{&quot;title&quot;:&quot;Soft prompts&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;conceptual_guides/prompting&quot;,&quot;url&quot;:&quot;/docs/peft/conceptual_guides/prompting&quot;},{&quot;title&quot;:&quot;IA3&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;conceptual_guides/ia3&quot;,&quot;url&quot;:&quot;/docs/peft/conceptual_guides/ia3&quot;},{&quot;title&quot;:&quot;OFT/BOFT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;conceptual_guides/oft&quot;,&quot;url&quot;:&quot;/docs/peft/conceptual_guides/oft&quot;}]},{&quot;title&quot;:&quot;API reference&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Main classes&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;AutoPeftModel&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/auto_class&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/auto_class&quot;},{&quot;title&quot;:&quot;PEFT model&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/peft_model&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/peft_model&quot;},{&quot;title&quot;:&quot;PEFT types&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/peft_types&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/peft_types&quot;},{&quot;title&quot;:&quot;Configuration&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/config&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/config&quot;},{&quot;title&quot;:&quot;Tuner&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/tuners&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/tuners&quot;}]},{&quot;title&quot;:&quot;Adapters&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;AdaLoRA&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/adalora&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/adalora&quot;},{&quot;title&quot;:&quot;IA3&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/ia3&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/ia3&quot;},{&quot;title&quot;:&quot;Llama-Adapter&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/llama_adapter&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/llama_adapter&quot;},{&quot;title&quot;:&quot;LoHa&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/loha&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/loha&quot;},{&quot;title&quot;:&quot;LoKr&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/lokr&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/lokr&quot;},{&quot;title&quot;:&quot;LoRA&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/lora&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/lora&quot;},{&quot;title&quot;:&quot;LyCORIS&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/adapter_utils&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/adapter_utils&quot;},{&quot;title&quot;:&quot;Multitask Prompt Tuning&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/multitask_prompt_tuning&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/multitask_prompt_tuning&quot;},{&quot;title&quot;:&quot;OFT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/oft&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/oft&quot;},{&quot;title&quot;:&quot;BOFT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/boft&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/boft&quot;},{&quot;title&quot;:&quot;Polytropon&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/poly&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/poly&quot;},{&quot;title&quot;:&quot;P-tuning&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/p_tuning&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/p_tuning&quot;},{&quot;title&quot;:&quot;Prefix tuning&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/prefix_tuning&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/prefix_tuning&quot;},{&quot;title&quot;:&quot;Prompt tuning&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/prompt_tuning&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/prompt_tuning&quot;},{&quot;title&quot;:&quot;Layernorm tuning&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/layernorm_tuning&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/layernorm_tuning&quot;},{&quot;title&quot;:&quot;VeRA&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/vera&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/vera&quot;},{&quot;title&quot;:&quot;Helpers&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/helpers&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/helpers&quot;}]},{&quot;title&quot;:&quot;Utilities&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Model merge&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;package_reference/merge_utils&quot;,&quot;url&quot;:&quot;/docs/peft/package_reference/merge_utils&quot;}]}]}],&quot;chapterId&quot;:&quot;index&quot;,&quot;docType&quot;:&quot;docs&quot;,&quot;isLoggedIn&quot;:false,&quot;lang&quot;:&quot;en&quot;,&quot;langs&quot;:[&quot;en&quot;],&quot;library&quot;:&quot;peft&quot;,&quot;theme&quot;:&quot;light&quot;,&quot;version&quot;:&quot;v0.11.0&quot;,&quot;versions&quot;:[{&quot;version&quot;:&quot;main&quot;},{&quot;version&quot;:&quot;v0.11.0&quot;},{&quot;version&quot;:&quot;v0.10.0&quot;},{&quot;version&quot;:&quot;v0.9.0&quot;},{&quot;version&quot;:&quot;v0.8.2&quot;},{&quot;version&quot;:&quot;v0.8.1&quot;},{&quot;version&quot;:&quot;v0.8.0&quot;},{&quot;version&quot;:&quot;v0.7.1&quot;},{&quot;version&quot;:&quot;v0.7.0&quot;},{&quot;version&quot;:&quot;v0.6.2&quot;},{&quot;version&quot;:&quot;v0.6.1&quot;},{&quot;version&quot;:&quot;v0.6.0&quot;}],&quot;title&quot;:&quot;PEFT&quot;}""> <div class=""z-2 w-full flex-none lg:block lg:h-screen lg:w-[270px] 2xl:w-[300px] false""><div class=""shadow-alternate flex h-16 w-full items-center rounded-b-xl border-b bg-white text-lg leading-tight lg:hidden""><div class=""flex flex-1 cursor-pointer flex-col justify-center self-stretch pl-6""><p class=""text-sm text-gray-400 first-letter:capitalize"">PEFT documentation</p> <div class=""flex items-center""><p class=""font-semibold"">Quicktour</p> <svg class=""text-xl false"" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 24 24""><path d=""M16.293 9.293L12 13.586L7.707 9.293l-1.414 1.414L12 16.414l5.707-5.707z"" fill=""currentColor""></path></svg></div></div> <button class=""hover:shadow-alternate group ml-auto mr-6 inline-flex flex-none cursor-pointer rounded-xl border p-2""><svg class=""text-gray-500 group-hover:text-gray-700"" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" focusable=""false"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 32 32""><path d=""M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z"" fill=""currentColor""></path></svg></button></div> <div class=""hidden h-32 flex-col justify-between border-b border-r bg-white bg-gradient-to-r p-4 lg:flex from-red-50 to-white dark:from-gray-900 dark:to-gray-950""><div class=""group relative flex min-w-[50%] items-center self-start text-lg font-bold leading-tight first-letter:capitalize""><div class=""mr-1.5 h-1.5 w-1.5 rounded-full bg-red-500 flex-none""></div> <h1>PEFT</h1> <svg class=""opacity-50 ml-0.5 flex-none group-hover:opacity-100"" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 24 24""><path d=""M16.293 9.293L12 13.586L7.707 9.293l-1.414 1.414L12 16.414l5.707-5.707z"" fill=""currentColor""></path></svg> <select class=""absolute inset-0 border-none bg-white text-base opacity-0 outline-none""><option value=""/docs"">🏡 View all docs</option><option value=""/docs/optimum-neuron"">AWS Trainium &amp; Inferentia</option><option value=""/docs/accelerate"">Accelerate</option><option value=""/docs/sagemaker"">Amazon SageMaker</option><option value=""/docs/autotrain"">AutoTrain</option><option value=""/docs/bitsandbytes"">Bitsandbytes</option><option value=""/docs/chat-ui"">Chat UI</option><option value=""/docs/competitions"">Competitions</option><option value=""/docs/datasets-server"">Dataset viewer</option><option value=""/docs/datasets"">Datasets</option><option value=""/docs/diffusers"">Diffusers</option><option value=""/docs/evaluate"">Evaluate</option><option value=""/docs/optimum-tpu"">Google TPUs</option><option value=""https://www.gradio.app/docs/"">Gradio</option><option value=""/docs/hub"">Hub</option><option value=""/docs/huggingface_hub"">Hub Python Library</option><option value=""/docs/huggingface.js"">Huggingface.js</option><option value=""/docs/api-inference"">Inference API (serverless)</option><option value=""/docs/inference-endpoints"">Inference Endpoints (dedicated)</option><option value=""/docs/optimum"">Optimum</option><option value=""/docs/peft"">PEFT</option><option value=""/docs/safetensors"">Safetensors</option><option value=""https://sbert.net/"">Sentence Transformers</option><option value=""/docs/trl"">TRL</option><option value=""/tasks"">Tasks</option><option value=""/docs/text-embeddings-inference"">Text Embeddings Inference</option><option value=""/docs/text-generation-inference"">Text Generation Inference</option><option value=""/docs/tokenizers"">Tokenizers</option><option value=""/docs/transformers"">Transformers</option><option value=""/docs/transformers.js"">Transformers.js</option><option value=""/docs/timm"">timm</option></select></div> <button class=""shadow-alternate flex w-full items-center rounded-full border bg-white px-2 py-1 text-left text-sm text-gray-400 ring-indigo-200 hover:bg-indigo-50 hover:ring-2 dark:border-gray-700 dark:ring-yellow-600 dark:hover:bg-gray-900 dark:hover:text-yellow-500""><svg class=""flex-none mr-1.5"" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" focusable=""false"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 32 32""><path d=""M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z"" fill=""currentColor""></path></svg> <div>Search documentation</div> <span class=""ml-auto rounded border border-gray-200 bg-gray-100 px-0.5 text-xs dark:border-gray-800 dark:bg-gray-800""><kbd class=""font-sans"">⌘K</kbd></span></button> <div class=""flex items-center""><select class=""form-input !mt-0 mr-1 !w-20 rounded !border border-gray-200 p-1 text-xs uppercase dark:!text-gray-400""><option value=""0"">main</option><option value=""1"">v0.11.0</option><option value=""2"">v0.10.0</option><option value=""3"">v0.9.0</option><option value=""4"">v0.8.2</option><option value=""5"">v0.7.1</option><option value=""6"">v0.6.2</option></select> <select class=""form-input mr-1 rounded border-gray-200 p-1 text-xs dark:!text-gray-400 !w-12 !mt-0 !border""><option value=""en"">EN</option></select> <div class=""relative inline-block""><button class=""rounded-full border border-gray-100 py-1 pl-2 pr-0.5 flex items-center text-sm text-gray-500 bg-white hover:bg-yellow-50 hover:border-yellow-200 dark:hover:bg-gray-800 dark:hover:border-gray-950 "" type=""button""><svg class=""mr-1.5 text-yellow-500"" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" focusable=""false"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 24 24"" fill=""currentColor""><path d=""M6.05 4.14l-.39-.39a.993.993 0 0 0-1.4 0l-.01.01a.984.984 0 0 0 0 1.4l.39.39c.39.39 1.01.39 1.4 0l.01-.01a.984.984 0 0 0 0-1.4zM3.01 10.5H1.99c-.55 0-.99.44-.99.99v.01c0 .55.44.99.99.99H3c.56.01 1-.43 1-.98v-.01c0-.56-.44-1-.99-1zm9-9.95H12c-.56 0-1 .44-1 .99v.96c0 .55.44.99.99.99H12c.56.01 1-.43 1-.98v-.97c0-.55-.44-.99-.99-.99zm7.74 3.21c-.39-.39-1.02-.39-1.41-.01l-.39.39a.984.984 0 0 0 0 1.4l.01.01c.39.39 1.02.39 1.4 0l.39-.39a.984.984 0 0 0 0-1.4zm-1.81 15.1l.39.39a.996.996 0 1 0 1.41-1.41l-.39-.39a.993.993 0 0 0-1.4 0c-.4.4-.4 1.02-.01 1.41zM20 11.49v.01c0 .55.44.99.99.99H22c.55 0 .99-.44.99-.99v-.01c0-.55-.44-.99-.99-.99h-1.01c-.55 0-.99.44-.99.99zM12 5.5c-3.31 0-6 2.69-6 6s2.69 6 6 6s6-2.69 6-6s-2.69-6-6-6zm-.01 16.95H12c.55 0 .99-.44.99-.99v-.96c0-.55-.44-.99-.99-.99h-.01c-.55 0-.99.44-.99.99v.96c0 .55.44.99.99.99zm-7.74-3.21c.39.39 1.02.39 1.41 0l.39-.39a.993.993 0 0 0 0-1.4l-.01-.01a.996.996 0 0 0-1.41 0l-.39.39c-.38.4-.38 1.02.01 1.41z""></path></svg>  </button> </div> <a href=""https://github.com/huggingface/peft"" class=""group ml-auto text-xs text-gray-500 hover:text-gray-700 hover:underline dark:hover:text-gray-300""><svg class=""inline-block text-gray-500 group-hover:text-gray-700 dark:group-hover:text-gray-300 mr-1.5 -mt-1 w-4 h-4"" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" focusable=""false"" role=""img"" width=""1.03em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 256 250""><path d=""M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46c6.397 1.185 8.746-2.777 8.746-6.158c0-3.052-.12-13.135-.174-23.83c-35.61 7.742-43.124-15.103-43.124-15.103c-5.823-14.795-14.213-18.73-14.213-18.73c-11.613-7.944.876-7.78.876-7.78c12.853.902 19.621 13.19 19.621 13.19c11.417 19.568 29.945 13.911 37.249 10.64c1.149-8.272 4.466-13.92 8.127-17.116c-28.431-3.236-58.318-14.212-58.318-63.258c0-13.975 5-25.394 13.188-34.358c-1.329-3.224-5.71-16.242 1.24-33.874c0 0 10.749-3.44 35.21 13.121c10.21-2.836 21.16-4.258 32.038-4.307c10.878.049 21.837 1.47 32.066 4.307c24.431-16.56 35.165-13.12 35.165-13.12c6.967 17.63 2.584 30.65 1.255 33.873c8.207 8.964 13.173 20.383 13.173 34.358c0 49.163-29.944 59.988-58.447 63.157c4.591 3.972 8.682 11.762 8.682 23.704c0 17.126-.148 30.91-.148 35.126c0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002C256 57.307 198.691 0 128.001 0zm-80.06 182.34c-.282.636-1.283.827-2.194.39c-.929-.417-1.45-1.284-1.15-1.922c.276-.655 1.279-.838 2.205-.399c.93.418 1.46 1.293 1.139 1.931zm6.296 5.618c-.61.566-1.804.303-2.614-.591c-.837-.892-.994-2.086-.375-2.66c.63-.566 1.787-.301 2.626.591c.838.903 1 2.088.363 2.66zm4.32 7.188c-.785.545-2.067.034-2.86-1.104c-.784-1.138-.784-2.503.017-3.05c.795-.547 2.058-.055 2.861 1.075c.782 1.157.782 2.522-.019 3.08zm7.304 8.325c-.701.774-2.196.566-3.29-.49c-1.119-1.032-1.43-2.496-.726-3.27c.71-.776 2.213-.558 3.315.49c1.11 1.03 1.45 2.505.701 3.27zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033c-1.448-.439-2.395-1.613-2.103-2.626c.301-1.01 1.747-1.484 3.207-1.028c1.446.436 2.396 1.602 2.095 2.622zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95c-1.53.034-2.769-.82-2.786-1.86c0-1.065 1.202-1.932 2.733-1.958c1.522-.03 2.768.818 2.768 1.868zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37c-1.485.271-2.861-.365-3.05-1.386c-.184-1.056.893-2.114 2.376-2.387c1.514-.263 2.868.356 3.061 1.403z"" fill=""currentColor""></path></svg> 14,474</a></div></div> <nav class=""top-32 hidden lg:flex absolute bottom-0 left-0 w-full flex-col overflow-y-auto border-r px-4 pb-16 pt-3 text-[0.95rem] lg:w-[270px] 2xl:w-[300px]""> <div class=""group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0""><div class=""flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['▶'] after:rotate-90 after:transform""><span><span class=""inline-block space-x-1 leading-5""><span>Get started</span> </span></span></div></div> <div class=""flex flex-col""><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/index"" id=""index"">🤗 PEFT </a><a class=""rounded-xl bg-gradient-to-br from-black to-gray-900 py-1 pl-2 pr-2 text-white first:mt-1 last:mb-4 dark:from-gray-800 dark:to-gray-900 ml-2"" href=""/docs/peft/quicktour"" id=""quicktour"">Quicktour </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/install"" id=""install"">Installation </a> </div><div class=""group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0""><div class=""flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['▶'] after:rotate-90 after:transform""><span><span class=""inline-block space-x-1 leading-5""><span>Tutorial</span> </span></span></div></div> <div class=""flex flex-col""><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/tutorial/peft_model_config"" id=""tutorial/peft_model_config"">Configurations and models </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/tutorial/peft_integrations"" id=""tutorial/peft_integrations"">Integrations </a> </div><div class=""group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0""><div class=""flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['▶'] after:rotate-90 after:transform""><span><span class=""inline-block space-x-1 leading-5""><span>PEFT method guides</span> </span></span></div></div> <div class=""flex flex-col""><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/task_guides/prompt_based_methods"" id=""task_guides/prompt_based_methods"">Prompt-based methods </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/task_guides/lora_based_methods"" id=""task_guides/lora_based_methods"">LoRA methods </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/task_guides/ia3"" id=""task_guides/ia3"">IA3 </a> </div><div class=""group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0""><div class=""flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['▶'] after:rotate-90 after:transform""><span><span class=""inline-block space-x-1 leading-5""><span>Developer guides</span> </span></span></div></div> <div class=""flex flex-col""><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/developer_guides/model_merging"" id=""developer_guides/model_merging"">Model merging </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/developer_guides/quantization"" id=""developer_guides/quantization"">Quantization </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/developer_guides/lora"" id=""developer_guides/lora"">LoRA </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/developer_guides/custom_models"" id=""developer_guides/custom_models"">Custom models </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/developer_guides/low_level_api"" id=""developer_guides/low_level_api"">Adapter injection </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/developer_guides/mixed_models"" id=""developer_guides/mixed_models"">Mixed adapter types </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/developer_guides/contributing"" id=""developer_guides/contributing"">Contribute to PEFT </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/developer_guides/troubleshooting"" id=""developer_guides/troubleshooting"">Troubleshooting </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/developer_guides/checkpoint"" id=""developer_guides/checkpoint"">PEFT checkpoint format </a> </div><div class=""group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0""><div class=""flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['▶'] after:rotate-90 after:transform""><span><span class=""inline-block space-x-1 leading-5""><span>🤗 Accelerate integrations</span> </span></span></div></div> <div class=""flex flex-col""><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/accelerate/deepspeed"" id=""accelerate/deepspeed"">DeepSpeed </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/accelerate/fsdp"" id=""accelerate/fsdp"">Fully Sharded Data Parallel </a> </div><div class=""group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0""><div class=""flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['▶'] after:rotate-90 after:transform""><span><span class=""inline-block space-x-1 leading-5""><span>Conceptual guides</span> </span></span></div></div> <div class=""flex flex-col""><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/conceptual_guides/adapter"" id=""conceptual_guides/adapter"">Adapters </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/conceptual_guides/prompting"" id=""conceptual_guides/prompting"">Soft prompts </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/conceptual_guides/ia3"" id=""conceptual_guides/ia3"">IA3 </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2"" href=""/docs/peft/conceptual_guides/oft"" id=""conceptual_guides/oft"">OFT/BOFT </a> </div><div class=""group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0""><div class=""flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['▶'] after:rotate-90 after:transform""><span><span class=""inline-block space-x-1 leading-5""><span>API reference</span> </span></span></div></div> <div class=""flex flex-col""><div class=""group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2""><div class=""flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['▶'] after:rotate-90 after:transform""><span><span class=""inline-block space-x-1 leading-5""><span>Main classes</span> </span></span></div></div> <div class=""flex flex-col""><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/auto_class"" id=""package_reference/auto_class"">AutoPeftModel </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/peft_model"" id=""package_reference/peft_model"">PEFT model </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/peft_types"" id=""package_reference/peft_types"">PEFT types </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/config"" id=""package_reference/config"">Configuration </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/tuners"" id=""package_reference/tuners"">Tuner </a> </div><div class=""group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2""><div class=""flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['▶'] after:rotate-90 after:transform""><span><span class=""inline-block space-x-1 leading-5""><span>Adapters</span> </span></span></div></div> <div class=""flex flex-col""><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/adalora"" id=""package_reference/adalora"">AdaLoRA </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/ia3"" id=""package_reference/ia3"">IA3 </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/llama_adapter"" id=""package_reference/llama_adapter"">Llama-Adapter </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/loha"" id=""package_reference/loha"">LoHa </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/lokr"" id=""package_reference/lokr"">LoKr </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/lora"" id=""package_reference/lora"">LoRA </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/adapter_utils"" id=""package_reference/adapter_utils"">LyCORIS </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/multitask_prompt_tuning"" id=""package_reference/multitask_prompt_tuning"">Multitask Prompt Tuning </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/oft"" id=""package_reference/oft"">OFT </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/boft"" id=""package_reference/boft"">BOFT </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/poly"" id=""package_reference/poly"">Polytropon </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/p_tuning"" id=""package_reference/p_tuning"">P-tuning </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/prefix_tuning"" id=""package_reference/prefix_tuning"">Prefix tuning </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/prompt_tuning"" id=""package_reference/prompt_tuning"">Prompt tuning </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/layernorm_tuning"" id=""package_reference/layernorm_tuning"">Layernorm tuning </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/vera"" id=""package_reference/vera"">VeRA </a><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/helpers"" id=""package_reference/helpers"">Helpers </a> </div><div class=""group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-2""><div class=""flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['▶'] after:rotate-90 after:transform""><span><span class=""inline-block space-x-1 leading-5""><span>Utilities</span> </span></span></div></div> <div class=""flex flex-col""><a class=""transform py-1 pl-2 pr-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-4"" href=""/docs/peft/package_reference/merge_utils"" id=""package_reference/merge_utils"">Model merge </a> </div> </div></nav></div></div></div>
		<div class=""z-1 min-w-0 flex-1"">
			<div class=""px-6 pt-6 md:px-12 md:pb-16 md:pt-16""><div class=""max-w-4xl mx-auto mb-10""><div class=""relative overflow-hidden rounded-xl bg-gradient-to-br from-orange-300/10 px-4 py-5 ring-1 ring-orange-100/70 md:px-6 md:py-8""><img alt=""Hugging Face's logo"" class=""absolute -bottom-6 -right-6 w-28 -rotate-45 md:hidden"" src=""/front/assets/huggingface_logo-noborder.svg"">
		<div class=""mb-2 text-2xl font-bold dark:text-gray-200 md:mb-0"">Join the Hugging Face community</div>
		<p class=""mb-4 text-lg text-gray-400 dark:text-gray-300 md:mb-8"">and get access to the augmented documentation experience
		</p>
		<div class=""mb-8 hidden space-y-4 md:block xl:flex xl:space-x-6 xl:space-y-0""><div class=""flex items-center""><div class=""mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg bg-gradient-to-br from-indigo-100 to-indigo-100/20 dark:to-indigo-100""><svg class=""text-indigo-400 group-hover:text-indigo-500"" style="""" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" focusable=""false"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 24 24""><path class=""uim-quaternary"" d=""M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z"" opacity="".25"" fill=""currentColor""></path><path class=""uim-tertiary"" d=""M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z"" opacity="".5"" fill=""currentColor""></path><path class=""uim-primary"" d=""M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z"" fill=""currentColor""></path></svg></div>
				<div class=""text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base"">Collaborate on models, datasets and Spaces
				</div></div>
			<div class=""flex items-center""><div class=""mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg bg-gradient-to-br from-orange-100 to-orange-100/20 dark:to-orange-50""><svg xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" focusable=""false"" role=""img"" class=""text-xl text-yellow-400"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 24 24""><path d=""M11 15H6l7-14v8h5l-7 14v-8z"" fill=""currentColor""></path></svg></div>
				<div class=""text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base"">Faster examples with accelerated inference
				</div></div>
			<div class=""flex items-center""><div class=""mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg bg-gradient-to-br from-gray-500/10 to-gray-500/5""><svg class=""text-gray-400"" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" focusable=""false"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 32 32""><path d=""M14.9804 3C14.9217 3.0002 14.8631 3.00555 14.8054 3.016C11.622 3.58252 8.76073 5.30669 6.77248 7.85653C4.78422 10.4064 3.80955 13.6016 4.03612 16.8271C4.26268 20.0525 5.67447 23.0801 7.99967 25.327C10.3249 27.5738 13.3991 28.8811 16.6304 28.997C16.7944 29.003 16.9584 28.997 17.1204 28.997C19.2193 28.9984 21.2877 28.4943 23.1507 27.5274C25.0137 26.5605 26.6164 25.1592 27.8234 23.442C27.9212 23.294 27.9783 23.1229 27.9889 22.9458C27.9995 22.7687 27.9633 22.592 27.884 22.4333C27.8046 22.2747 27.6848 22.1397 27.5367 22.0421C27.3887 21.9444 27.2175 21.8875 27.0404 21.877C25.0426 21.7017 23.112 21.0693 21.3976 20.0288C19.6832 18.9884 18.231 17.5676 17.1533 15.8764C16.0756 14.1852 15.4011 12.2688 15.1822 10.2754C14.9632 8.28193 15.2055 6.26484 15.8904 4.38C15.9486 4.22913 15.97 4.06652 15.9527 3.90572C15.9354 3.74492 15.8799 3.59059 15.7909 3.45557C15.7019 3.32055 15.5819 3.20877 15.4409 3.12952C15.2999 3.05028 15.142 3.00587 14.9804 3Z"" fill=""currentColor""></path></svg></div>
				<div class=""text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base"">Switch between documentation themes
				</div></div></div>
		<div class=""flex items-center space-x-2.5""><a href=""/join""><button class=""rounded-lg bg-white bg-gradient-to-br from-gray-100/20 to-gray-200/60 px-5 py-1.5 font-semibold text-gray-700 shadow-sm ring-1 ring-gray-300/60 hover:to-gray-100/70 hover:ring-gray-300/30 active:shadow-inner"">Sign Up</button></a>
			<p class=""text-gray-500 dark:text-gray-300"">to get started</p></div></div></div>
				<div class=""prose-doc prose relative mx-auto max-w-4xl break-words""> <p></p> <h1 class=""relative group""><a id=""quicktour"" class=""header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"" href=""#quicktour""><span><svg class="""" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 256 256""><path d=""M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"" fill=""currentColor""></path></svg></span></a> <span>Quicktour</span></h1> <p>PEFT offers parameter-efficient methods for finetuning large pretrained models. The traditional paradigm is to finetune all of a model’s parameters for each downstream task, but this is becoming exceedingly costly and impractical because of the enormous number of parameters in models today. Instead, it is more efficient to train a smaller number of prompt parameters or use a reparametrization method like low-rank adaptation (LoRA) to reduce the number of trainable parameters.</p> <p>This quicktour will show you PEFT’s main features and how you can train or run inference on large models that would typically be inaccessible on consumer devices.</p> <h2 class=""relative group""><a id=""train"" class=""header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"" href=""#train""><span><svg class="""" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 256 256""><path d=""M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"" fill=""currentColor""></path></svg></span></a> <span>Train</span></h2> <p>Each PEFT method is defined by a <a href=""/docs/peft/v0.11.0/en/package_reference/config#peft.PeftConfig"">PeftConfig</a> class that stores all the important parameters for building a <a href=""/docs/peft/v0.11.0/en/package_reference/peft_model#peft.PeftModel"">PeftModel</a>. For example, to train with LoRA, load and create a <a href=""/docs/peft/v0.11.0/en/package_reference/lora#peft.LoraConfig"">LoraConfig</a> class and specify the following parameters:</p> <ul><li><code>task_type</code>: the task to train for (sequence-to-sequence language modeling in this case)</li> <li><code>inference_mode</code>: whether you’re using the model for inference or not</li> <li><code>r</code>: the dimension of the low-rank matrices</li> <li><code>lora_alpha</code>: the scaling factor for the low-rank matrices</li> <li><code>lora_dropout</code>: the dropout probability of the LoRA layers</li></ul> <div class=""code-block relative""><div class=""absolute top-2.5 right-4""><button class=""inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 "" title=""code excerpt"" type=""button""><svg class="""" xmlns=""http://www.w3.org/2000/svg"" aria-hidden=""true"" fill=""currentColor"" focusable=""false"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 32 32""><path d=""M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z"" transform=""translate(0)""></path><path d=""M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z"" transform=""translate(0)""></path><rect fill=""none"" width=""32"" height=""32""></rect></svg> <div class=""absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0""><div class=""absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0"" style=""border-left-color: transparent; border-right-color: transparent;""></div> Copied</div></button></div> <pre class=""""><span class=""hljs-keyword"">from</span> peft <span class=""hljs-keyword"">import</span> LoraConfig, TaskType

peft_config = LoraConfig(task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=<span class=""hljs-literal"">False</span>, r=<span class=""hljs-number"">8</span>, lora_alpha=<span class=""hljs-number"">32</span>, lora_dropout=<span class=""hljs-number"">0.1</span>)</pre></div> <div class=""course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400""><p>See the <a href=""/docs/peft/v0.11.0/en/package_reference/lora#peft.LoraConfig"">LoraConfig</a> reference for more details about other parameters you can adjust, such as the modules to target or the bias type.</p></div> <p>Once the <a href=""/docs/peft/v0.11.0/en/package_reference/lora#peft.LoraConfig"">LoraConfig</a> is setup, create a <a href=""/docs/peft/v0.11.0/en/package_reference/peft_model#peft.PeftModel"">PeftModel</a> with the <a href=""/docs/peft/v0.11.0/en/package_reference/peft_model#peft.get_peft_model"">get_peft_model()</a> function. It takes a base model - which you can load from the Transformers library - and the <a href=""/docs/peft/v0.11.0/en/package_reference/lora#peft.LoraConfig"">LoraConfig</a> containing the parameters for how to configure a model for training with LoRA.</p> <p>Load the base model you want to finetune.</p> <div class=""code-block relative""><div class=""absolute top-2.5 right-4""><button class=""inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 "" title=""code excerpt"" type=""button""><svg class="""" xmlns=""http://www.w3.org/2000/svg"" aria-hidden=""true"" fill=""currentColor"" focusable=""false"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 32 32""><path d=""M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z"" transform=""translate(0)""></path><path d=""M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z"" transform=""translate(0)""></path><rect fill=""none"" width=""32"" height=""32""></rect></svg> <div class=""absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0""><div class=""absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0"" style=""border-left-color: transparent; border-right-color: transparent;""></div> Copied</div></button></div> <pre class=""""><span class=""hljs-keyword"">from</span> transformers <span class=""hljs-keyword"">import</span> AutoModelForSeq2SeqLM

model = AutoModelForSeq2SeqLM.from_pretrained(<span class=""hljs-string"">""bigscience/mt0-large""</span>)</pre></div> <p>Wrap the base model and <code>peft_config</code> with the <a href=""/docs/peft/v0.11.0/en/package_reference/peft_model#peft.get_peft_model"">get_peft_model()</a> function to create a <a href=""/docs/peft/v0.11.0/en/package_reference/peft_model#peft.PeftModel"">PeftModel</a>. To get a sense of the number of trainable parameters in your model, use the <code>print_trainable_parameters</code> method.</p> <div class=""code-block relative""><div class=""absolute top-2.5 right-4""><button class=""inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 "" title=""code excerpt"" type=""button""><svg class="""" xmlns=""http://www.w3.org/2000/svg"" aria-hidden=""true"" fill=""currentColor"" focusable=""false"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 32 32""><path d=""M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z"" transform=""translate(0)""></path><path d=""M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z"" transform=""translate(0)""></path><rect fill=""none"" width=""32"" height=""32""></rect></svg> <div class=""absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0""><div class=""absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0"" style=""border-left-color: transparent; border-right-color: transparent;""></div> Copied</div></button></div> <pre class=""""><span class=""hljs-keyword"">from</span> peft <span class=""hljs-keyword"">import</span> get_peft_model

model = get_peft_model(model, peft_config)
model.print_trainable_parameters()
<span class=""hljs-string"">""output: trainable params: 2359296 || all params: 1231940608 || trainable%: 0.19151053100118282""</span></pre></div> <p>Out of <a href=""https://huggingface.co/bigscience/mt0-large"" rel=""nofollow"">bigscience/mt0-large’s</a> 1.2B parameters, you’re only training 0.19% of them!</p> <p>That is it 🎉! Now you can train the model with the Transformers <a href=""https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/trainer#transformers.Trainer"" rel=""nofollow"">Trainer</a>, Accelerate, or any custom PyTorch training loop.</p> <p>For example, to train with the <a href=""https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/trainer#transformers.Trainer"" rel=""nofollow"">Trainer</a> class, setup a <a href=""https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/trainer#transformers.TrainingArguments"" rel=""nofollow"">TrainingArguments</a> class with some training hyperparameters.</p> <div class=""code-block relative""><div class=""absolute top-2.5 right-4""><button class=""inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 "" title=""code excerpt"" type=""button""><svg class="""" xmlns=""http://www.w3.org/2000/svg"" aria-hidden=""true"" fill=""currentColor"" focusable=""false"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 32 32""><path d=""M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z"" transform=""translate(0)""></path><path d=""M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z"" transform=""translate(0)""></path><rect fill=""none"" width=""32"" height=""32""></rect></svg> <div class=""absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0""><div class=""absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0"" style=""border-left-color: transparent; border-right-color: transparent;""></div> Copied</div></button></div> <pre class="""">training_args = TrainingArguments(
    output_dir=<span class=""hljs-string"">""your-name/bigscience/mt0-large-lora""</span>,
    learning_rate=<span class=""hljs-number"">1e-3</span>,
    per_device_train_batch_size=<span class=""hljs-number"">32</span>,
    per_device_eval_batch_size=<span class=""hljs-number"">32</span>,
    num_train_epochs=<span class=""hljs-number"">2</span>,
    weight_decay=<span class=""hljs-number"">0.01</span>,
    evaluation_strategy=<span class=""hljs-string"">""epoch""</span>,
    save_strategy=<span class=""hljs-string"">""epoch""</span>,
    load_best_model_at_end=<span class=""hljs-literal"">True</span>,
)</pre></div> <p>Pass the model, training arguments, dataset, tokenizer, and any other necessary component to the <a href=""https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/trainer#transformers.Trainer"" rel=""nofollow"">Trainer</a>, and call <a href=""https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/trainer#transformers.Trainer.train"" rel=""nofollow"">train</a> to start training.</p> <div class=""code-block relative""><div class=""absolute top-2.5 right-4""><button class=""inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 "" title=""code excerpt"" type=""button""><svg class="""" xmlns=""http://www.w3.org/2000/svg"" aria-hidden=""true"" fill=""currentColor"" focusable=""false"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 32 32""><path d=""M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z"" transform=""translate(0)""></path><path d=""M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z"" transform=""translate(0)""></path><rect fill=""none"" width=""32"" height=""32""></rect></svg> <div class=""absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0""><div class=""absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0"" style=""border-left-color: transparent; border-right-color: transparent;""></div> Copied</div></button></div> <pre class="""">trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets[<span class=""hljs-string"">""train""</span>],
    eval_dataset=tokenized_datasets[<span class=""hljs-string"">""test""</span>],
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics,
)

trainer.train()</pre></div> <h3 class=""relative group""><a id=""save-model"" class=""header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"" href=""#save-model""><span><svg class="""" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 256 256""><path d=""M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"" fill=""currentColor""></path></svg></span></a> <span>Save model</span></h3> <p>After your model is finished training, you can save your model to a directory using the <a href=""https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/model#transformers.PreTrainedModel.save_pretrained"" rel=""nofollow"">save_pretrained</a> function.</p> <div class=""code-block relative""><div class=""absolute top-2.5 right-4""><button class=""inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 "" title=""code excerpt"" type=""button""><svg class="""" xmlns=""http://www.w3.org/2000/svg"" aria-hidden=""true"" fill=""currentColor"" focusable=""false"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 32 32""><path d=""M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z"" transform=""translate(0)""></path><path d=""M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z"" transform=""translate(0)""></path><rect fill=""none"" width=""32"" height=""32""></rect></svg> <div class=""absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0""><div class=""absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0"" style=""border-left-color: transparent; border-right-color: transparent;""></div> Copied</div></button></div> <pre class="""">model.save_pretrained(<span class=""hljs-string"">""output_dir""</span>)</pre></div> <p>You can also save your model to the Hub (make sure you’re logged in to your Hugging Face account first) with the <a href=""https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/model#transformers.PreTrainedModel.push_to_hub"" rel=""nofollow"">push_to_hub</a> function.</p> <div class=""code-block relative""><div class=""absolute top-2.5 right-4""><button class=""inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 "" title=""code excerpt"" type=""button""><svg class="""" xmlns=""http://www.w3.org/2000/svg"" aria-hidden=""true"" fill=""currentColor"" focusable=""false"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 32 32""><path d=""M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z"" transform=""translate(0)""></path><path d=""M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z"" transform=""translate(0)""></path><rect fill=""none"" width=""32"" height=""32""></rect></svg> <div class=""absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0""><div class=""absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0"" style=""border-left-color: transparent; border-right-color: transparent;""></div> Copied</div></button></div> <pre class=""""><span class=""hljs-keyword"">from</span> huggingface_hub <span class=""hljs-keyword"">import</span> notebook_login

notebook_login()
model.push_to_hub(<span class=""hljs-string"">""your-name/bigscience/mt0-large-lora""</span>)</pre></div> <p>Both methods only save the extra PEFT weights that were trained, meaning it is super efficient to store, transfer, and load. For example, this <a href=""https://huggingface.co/ybelkada/opt-350m-lora"" rel=""nofollow"">facebook/opt-350m</a> model trained with LoRA only contains two files: <code>adapter_config.json</code> and <code>adapter_model.safetensors</code>. The <code>adapter_model.safetensors</code> file is just 6.3MB!</p> <div class=""flex flex-col justify-center""><img src=""https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/peft/PEFT-hub-screenshot.png""> <figcaption class=""text-center"">The adapter weights for a opt-350m model stored on the Hub are only ~6MB compared to the full size of the model weights, which can be ~700MB.</figcaption></div> <h2 class=""relative group""><a id=""inference"" class=""header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"" href=""#inference""><span><svg class="""" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 256 256""><path d=""M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"" fill=""currentColor""></path></svg></span></a> <span>Inference</span></h2> <div class=""course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400""><p>Take a look at the <a href=""package_reference/auto_class"">AutoPeftModel</a> API reference for a complete list of available <code>AutoPeftModel</code> classes.</p></div> <p>Easily load any PEFT-trained model for inference with the <a href=""/docs/peft/v0.11.0/en/package_reference/auto_class#peft.AutoPeftModel"">AutoPeftModel</a> class and the <a href=""https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/model#transformers.PreTrainedModel.from_pretrained"" rel=""nofollow"">from_pretrained</a> method:</p> <div class=""code-block relative""><div class=""absolute top-2.5 right-4""><button class=""inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 "" title=""code excerpt"" type=""button""><svg class="""" xmlns=""http://www.w3.org/2000/svg"" aria-hidden=""true"" fill=""currentColor"" focusable=""false"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 32 32""><path d=""M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z"" transform=""translate(0)""></path><path d=""M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z"" transform=""translate(0)""></path><rect fill=""none"" width=""32"" height=""32""></rect></svg> <div class=""absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0""><div class=""absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0"" style=""border-left-color: transparent; border-right-color: transparent;""></div> Copied</div></button></div> <pre class=""""><span class=""hljs-keyword"">from</span> peft <span class=""hljs-keyword"">import</span> AutoPeftModelForCausalLM
<span class=""hljs-keyword"">from</span> transformers <span class=""hljs-keyword"">import</span> AutoTokenizer
<span class=""hljs-keyword"">import</span> torch

model = AutoPeftModelForCausalLM.from_pretrained(<span class=""hljs-string"">""ybelkada/opt-350m-lora""</span>)
tokenizer = AutoTokenizer.from_pretrained(<span class=""hljs-string"">""facebook/opt-350m""</span>)

model = model.to(<span class=""hljs-string"">""cuda""</span>)
model.<span class=""hljs-built_in"">eval</span>()
inputs = tokenizer(<span class=""hljs-string"">""Preheat the oven to 350 degrees and place the cookie dough""</span>, return_tensors=<span class=""hljs-string"">""pt""</span>)

outputs = model.generate(input_ids=inputs[<span class=""hljs-string"">""input_ids""</span>].to(<span class=""hljs-string"">""cuda""</span>), max_new_tokens=<span class=""hljs-number"">50</span>)
<span class=""hljs-built_in"">print</span>(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=<span class=""hljs-literal"">True</span>)[<span class=""hljs-number"">0</span>])

<span class=""hljs-string"">""Preheat the oven to 350 degrees and place the cookie dough in the center of the oven. In a large bowl, combine the flour, baking powder, baking soda, salt, and cinnamon. In a separate bowl, combine the egg yolks, sugar, and vanilla.""</span></pre></div> <p>For other tasks that aren’t explicitly supported with an <code>AutoPeftModelFor</code> class - such as automatic speech recognition - you can still use the base <a href=""/docs/peft/v0.11.0/en/package_reference/auto_class#peft.AutoPeftModel"">AutoPeftModel</a> class to load a model for the task.</p> <div class=""code-block relative""><div class=""absolute top-2.5 right-4""><button class=""inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 "" title=""code excerpt"" type=""button""><svg class="""" xmlns=""http://www.w3.org/2000/svg"" aria-hidden=""true"" fill=""currentColor"" focusable=""false"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 32 32""><path d=""M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z"" transform=""translate(0)""></path><path d=""M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z"" transform=""translate(0)""></path><rect fill=""none"" width=""32"" height=""32""></rect></svg> <div class=""absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0""><div class=""absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0"" style=""border-left-color: transparent; border-right-color: transparent;""></div> Copied</div></button></div> <pre class=""""><span class=""hljs-keyword"">from</span> peft <span class=""hljs-keyword"">import</span> AutoPeftModel

model = AutoPeftModel.from_pretrained(<span class=""hljs-string"">""smangrul/openai-whisper-large-v2-LORA-colab""</span>)</pre></div> <h2 class=""relative group""><a id=""next-steps"" class=""header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"" href=""#next-steps""><span><svg class="""" xmlns=""http://www.w3.org/2000/svg"" xmlns:xlink=""http://www.w3.org/1999/xlink"" aria-hidden=""true"" role=""img"" width=""1em"" height=""1em"" preserveAspectRatio=""xMidYMid meet"" viewBox=""0 0 256 256""><path d=""M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z"" fill=""currentColor""></path></svg></span></a> <span>Next steps</span></h2> <p>Now that you’ve seen how to train a model with one of the PEFT methods, we encourage you to try out some of the other methods like prompt tuning. The steps are very similar to the ones shown in the quicktour:</p> <ol><li>prepare a <a href=""/docs/peft/v0.11.0/en/package_reference/config#peft.PeftConfig"">PeftConfig</a> for a PEFT method</li> <li>use the <a href=""/docs/peft/v0.11.0/en/package_reference/peft_model#peft.get_peft_model"">get_peft_model()</a> method to create a <a href=""/docs/peft/v0.11.0/en/package_reference/peft_model#peft.PeftModel"">PeftModel</a> from the configuration and base model</li></ol> <p>Then you can train it however you like! To load a PEFT model for inference, you can use the <a href=""/docs/peft/v0.11.0/en/package_reference/auto_class#peft.AutoPeftModel"">AutoPeftModel</a> class.</p> <p>Feel free to also take a look at the task guides if you’re interested in training a model with another PEFT method for a specific task such as semantic segmentation, multilingual automatic speech recognition, DreamBooth, token classification, and more.</p> <a class=""!text-gray-400 !no-underline text-sm flex items-center not-prose mt-4"" href=""https://github.com/huggingface/peft/blob/main/docs/source/quicktour.md"" target=""_blank""><span>&lt;</span> <span>&gt;</span> <span><span class=""underline ml-1.5"">Update</span> on GitHub</span></a> <p></p> <div id=""svelte-announcer"" aria-live=""assertive"" aria-atomic=""true"" style=""position: absolute; left: 0px; top: 0px; clip: rect(0px, 0px, 0px, 0px); clip-path: inset(50%); overflow: hidden; white-space: nowrap; width: 1px; height: 1px;"">Quicktour</div></div>
				<div class=""SVELTE_HYDRATER contents"" data-target=""DocFooterNav"" data-props=""{&quot;classNames&quot;:&quot;mx-auto mt-16 flex max-w-4xl items-center pb-8 font-sans font-medium leading-6 xl:mt-32&quot;,&quot;chapterNext&quot;:{&quot;title&quot;:&quot;Quicktour&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;quicktour&quot;,&quot;url&quot;:&quot;/docs/peft/quicktour&quot;},&quot;isCourse&quot;:false,&quot;isLoggedIn&quot;:false}""><div class=""mx-auto mt-16 flex max-w-4xl items-center pb-8 font-sans font-medium leading-6 xl:mt-32""><a href=""/docs/peft/index"" class=""mr-8 flex transform items-center text-gray-600 transition-all hover:-translate-x-px hover:text-gray-900 dark:hover:text-gray-300""><span class=""mr-2 translate-y-px"">←</span>🤗 PEFT</a> <a href=""/docs/peft/install"" class=""ml-auto flex transform items-center text-right text-gray-600 transition-all hover:translate-x-px hover:text-gray-900 dark:hover:text-gray-300"">Installation<span class=""ml-2 translate-y-px"">→</span></a></div></div></div></div>
		<div class=""sticky top-0 self-start""><div class=""SVELTE_HYDRATER contents"" data-target=""SubSideMenu"" data-props=""{&quot;chapter&quot;:{&quot;title&quot;:&quot;PEFT&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;peft&quot;,&quot;url&quot;:&quot;#peft&quot;,&quot;sections&quot;:[]}}""><nav class=""hidden h-screen w-[270px] flex-none flex-col space-y-3 overflow-y-auto break-words border-l pb-16 pl-6 pr-10 pt-24 text-sm lg:flex 2xl:w-[305px]""><a href=""#quicktour"" class="" text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300"" id=""nav-quicktour""><wbr>Quicktour</a> <a href=""#train"" class=""pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300"" id=""nav-train""><wbr>Train</a> <a href=""#save-model"" class=""pl-8 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300"" id=""nav-save-model""><wbr>Save model</a> <a href=""#inference"" class=""pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300"" id=""nav-inference""><wbr>Inference</a> <a href=""#next-steps"" class=""pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300"" id=""nav-next-steps""><wbr>Next steps</a> </nav></div></div></div>
	<div id=""doc-footer""></div></main>

	</div>

		<script>
			import(""/front/build/kube-ffab781/index.js"");
			window.moonSha = ""kube-ffab781/"";
			window.hubConfig = JSON.parse(`{""features"":{""signupDisabled"":false},""sshGitUrl"":""git@hf.co"",""moonHttpUrl"":""https://huggingface.co"",""captchaApiKey"":""bd5f2066-93dc-4bdd-a64b-a24646ca3859"",""captchaDisabledOnSignup"":true,""datasetViewerPublicUrl"":""https://datasets-server.huggingface.co"",""stripePublicKey"":""pk_live_x2tdjFXBCvXo2FFmMybezpeM00J6gPCAAc"",""environment"":""production"",""userAgent"":""HuggingFace (production)"",""spacesIframeDomain"":""hf.space"",""spacesApiUrl"":""https://api.hf.space""}`);
		</script>

		<!-- Stripe -->
		<script>
			if ([""hf.co"", ""huggingface.co""].includes(window.location.hostname)) {
				const script = document.createElement(""script"");
				script.src = ""https://js.stripe.com/v3/"";
				script.async = true;
				document.head.appendChild(script);
			}
		</script>
	

<iframe name=""__privateStripeMetricsController0750"" frameborder=""0"" allowtransparency=""true"" scrolling=""no"" role=""presentation"" allow=""payment *"" src=""https://js.stripe.com/v3/m-outer-3437aaddcdf6922d623e172c2d6f9278.html#url=https%3A%2F%2Fhuggingface.co%2Fdocs%2Fpeft%2Findex&amp;title=PEFT&amp;referrer=https%3A%2F%2Fhuggingface.co%2Fdocs&amp;muid=776e885c-59b1-41c9-96e5-d6c3c7a3dcc6cac054&amp;sid=3301390b-2f42-476b-83a4-6cc39ab4e8f4d05edb&amp;version=6&amp;preview=false"" aria-hidden=""true"" tabindex=""-1"" style=""border: none !important; margin: 0px !important; padding: 0px !important; width: 1px !important; min-width: 100% !important; overflow: hidden !important; display: block !important; visibility: hidden !important; position: fixed !important; height: 1px !important; pointer-events: none !important; user-select: none !important;""></iframe></body></html>"
screenshots_path,screenshots/https_huggingface.co_docs_peft_quicktour
url,https://huggingface.co/docs/peft/quicktour
date,2024-06-04T21:47:44.196180
run_id,95930ca2-4849-4f11-a953-8cd0e20c57ad
step,3
screenshots,[<PIL.PngImagePlugin.PngImageFile image mode=RGB size=2048x2048 at 0x156A4F190>]
